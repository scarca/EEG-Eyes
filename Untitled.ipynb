{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "data_o = pd.read_csv(\"data.arff\", skiprows=19, header=None)\n",
    "data_o.columns = [\"AF3\", \"F7\", \"F3\", \"FC5\", \"T7\", \"P7\", \"O1\", \"O2\", \"P8\", \"T8\", \"FC6\", \"F4\", \"F8\", \"AF4\", \"E\" ]\n",
    "x_cols =  [\"AF3\", \"F7\", \"F3\", \"FC5\", \"T7\", \"P7\", \"O1\", \"O2\", \"P8\", \"T8\", \"FC6\", \"F4\", \"F8\", \"AF4\"]\n",
    "for i in range(0, 3): \n",
    "    for j, col in enumerate(x_cols): \n",
    "        amax = data_o[col].idxmax() \n",
    "        data_o.iloc[amax, j] = (data_o.iloc[amax - 1, j] + data_o.iloc[amax + 1, j]) / 2\n",
    "        amin = data_o[col].idxmin() \n",
    "        data_o.iloc[amin, j] = (data_o.iloc[amin - 1, j] + data_o.iloc[amin + 1, j]) / 2\n",
    "new = {}; \n",
    "for i in data_o:\n",
    "    if i != \"E\": \n",
    "        new[i] = (data_o[i] - data_o[i].median())/data_o[i].std() \n",
    "    else: \n",
    "        new[i] = data_o[i] \n",
    "data = pd.DataFrame(new) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "input_vector = np.zeros((data_o.shape[0] - shape[0], np.prod(shape)))\n",
    "output_vector = np.zeros((data_o.shape[0] - shape[0], 1))\n",
    "\n",
    "for i in range(shape[0], data_o.shape[0]): \n",
    "    input_vector[i - shape[0], :] = data.iloc[i - shape[0]:i, :-1].values.flatten()\n",
    "    output_vector[i - shape[0]] = data['E'][i].astype(int)\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(input_vector, output_vector)\n",
    "\n",
    "def model_func(mode): \n",
    "    x = tf.placeholder(tf.float32, [None, input_vector.shape[1]])\n",
    "    \n",
    "    dense1 = tf.layers.dense( \n",
    "        inputs = x, \n",
    "        units = int(np.sqrt(np.prod(shape))) * 2, \n",
    "        activation = tf.nn.sigmoid, \n",
    "        name=\"Input_Activation\"\n",
    "    )\n",
    "    # Reactivate with softplus to let any startlingly high inputs\n",
    "    # be amplified \n",
    "    second_seg = tf.layers.dense(\n",
    "        inputs = dense1,\n",
    "        units = int(np.sqrt(np.prod(shape))), \n",
    "        activation = tf.nn.softplus, \n",
    "        name=\"Softplus\"\n",
    "    )\n",
    "\n",
    "    # Dropout -- softplus seems dangerous  \n",
    "    dropout = tf.layers.dropout (\n",
    "        inputs = second_seg, \n",
    "        rate = 0.25, \n",
    "        training= mode == tf.estimator.ModeKeys.TRAIN, \n",
    "        name=\"Dropout\"\n",
    "    )\n",
    "\n",
    "    # Reactivate the softplus  \n",
    "    dense2 = tf.layers.dense(\n",
    "        inputs = dropout,\n",
    "        units = int(np.sqrt(np.prod(shape))), \n",
    "        activation = tf.nn.tanh, \n",
    "        name=\"Dense_Layer_sqrt_X\"\n",
    "    )\n",
    "    # And once more, with an arbitrarly large layer. \n",
    "    dense3 = tf.layers.dense (\n",
    "        inputs = dense2, \n",
    "        units = 1000, \n",
    "        activation = tf.nn.tanh, \n",
    "        name=\"Dense_Layer_1000\"\n",
    "    )\n",
    "    #Compact this with ReLU into our output.  \n",
    "    res = tf.layers.dense (\n",
    "        inputs = dense3, \n",
    "        activation = tf.nn.relu,\n",
    "        units = 2,\n",
    "        name=\"Output\"\n",
    "    )\n",
    "    \n",
    "    predictions = {\n",
    "        'classes': tf.argmax(input=res, axis=1), \n",
    "        'probabilities': tf.nn.softmax(res, name=\"softmax_tensor\") \n",
    "    }\n",
    "    \n",
    "    if mode == \"PREDICT\":\n",
    "        return (x, predictions)\n",
    "    labels = tf.placeholder(tf.float32, [None, 1]) \n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels = labels, logits = res)\n",
    "    \n",
    "    if mode == \"TRAIN\": \n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data]",
   "language": "python",
   "name": "conda-env-data-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
